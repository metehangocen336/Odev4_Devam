{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a1197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meteh\\AppData\\Local\\Temp\\ipykernel_6532\\1855853058.py:126: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Etiketleme tamamlandı → llama-3.3-70b-versatile_output1.csv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Groq istemcisini başlat\n",
    "client = Groq(\n",
    "    api_key=\"your_api_key\"  # Kendi Groq API anahtarınızı kullanın\n",
    ")\n",
    "\n",
    "# === MODEL ===\n",
    "MODEL = \"llama-3.3-70b-versatile\" # Önerilen model\n",
    "\n",
    "# === PROMPT OLUŞTURMA ===\n",
    "def prompt_olusturSentiment(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki user ve bot görüşmesini mesajda botun kullanıcıya yansıtmadığı düşünceleride var bir düğün analizi uzmanı gibi analiz et analiz sonucunu yazmana gerek yok ve userın konuşma mesajlarındaki sentimentine göre sentiment  etiketini ver sadece,\n",
    "sentiment: [Pozitif / Negatif / Nötr]\n",
    "Sentimenti Tek tek mesajlardan değilde konuşmanın geneline bakarak değerlendir ama her mesajı analiz et.\n",
    "Sentiment Etiket Üretme Mantığı: Göndericinin user olduğu mesajlarda tamamen olumlu kesin olarak pozitif anlam içeriyorsa pozitif etiketle,göndericininin user olduğu mesajlarda genel olarak net bir şekilde negatif durumlar varsa negatif etiketle,bunlar dışındakileri yani user bot konuşmaları genelinde net olarak pozitif değilse, net olarak negatif değilse nötr etiketle.\n",
    "Cevabı Türkçe oluştur:Sadece sentiment=pozitif, sentiment=negatif veya sentiment=nötr gibi analiz sonucunun yorumunu yapma:\n",
    "\n",
    "Mesaj: \"{mesaj}\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def promptOlusturKonu(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki user ve bot  görüşmesi mesajını bir düğün analizi uzmanı gibi analiz et analiz sonucunu yazmana gerek yok mesj boyunca konusulan ilgili konuları liste olarak ver:\n",
    "\n",
    "Mesaj: \"{mesaj}\"\n",
    "\n",
    "Konu: . Etkinlik Türüyle İlgili Kelimeler\n",
    "(düğün, düğün salonu, düğün mekanı, kır düğünü, havuz başı düğün, otel düğünü\n",
    "kına, kına gecesi, kına organizasyonu, kına mekanı\n",
    "nişan, nişan organizasyonu, nişan mekanı, söz\n",
    "sünnet, sünnet düğünü, sünnet organizasyonu\n",
    "doğum günü, baby shower, mezuniyet, parti, after party\n",
    "2. Hizmet Türüyle İlgili Kelimeler\n",
    "organizasyon, organizasyon firması, düğün organizasyonu, kına organizasyonu\n",
    "fotoğrafçı, düğün fotoğrafçısı, video, çekim, klip\n",
    "davetiye, nikah şekeri, gelin arabası, gelin buketi, gelinlik, damatlık, saç-makyaj\n",
    "orkestra, DJ, müzik grubu, catering, yemek, kokteyl, pasta\n",
    "balayı, balayı oteli, balayı villası\n",
    "3. Mekan ve Lokasyonla İlgili Kelimeler\n",
    "il, ilçe, semt adı (ör: İstanbul, Beylikdüzü, Kadıköy, İzmir, Ankara, Bursa)\n",
    "açık alan, kapalı alan, bahçe, salon, villa, tarihi mekan, sosyal tesis, otel, tekne, havuz başı\n",
    "yakın, çevre, komşu ilçeler\n",
    "4. Tarih ve Zamanla İlgili Kelimeler\n",
    "tarih, gün, hafta sonu, hafta içi, yaz, kış, ay ismi (ör: Haziran, Temmuz)\n",
    "5. Bütçe ve Kapasiteyle İlgili Kelimeler\n",
    "kişi başı, toplam bütçe, fiyat, ücret, uygun fiyatlı, lüks, ekonomik\n",
    "davetli sayısı, kapasite, küçük grup, kalabalık, az kişi, çok kişi\n",
    "6. İkram ve Menüyle İlgili Kelimeler\n",
    "yemekli, yemeksiz, kokteyl, pasta, meşrubat, açık büfe, içecek, ikram)\n",
    "\n",
    "Türkçe olarak bir konu listesi üret, sadece listele, ve mesajda net olarak beliritlen konuyu seç mesaj dışı konular ekleme, yorum yapma: konu=[konu listesi] gibi sadece liste\n",
    "\"\"\"\n",
    "\n",
    "def prompt_olusturYanitladimi(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki bütün müşteri bot konuşmalarını analiz et ama analiz sonuçlarını yazmana gerek yok ve gelen konuşmalarda botun userın sorularını yanıtlayıp yanıtlamadığını kontrol et konuşma boyunca userdan sonraki ilk gönderici botsa cevaplandı kabul edebilrisin:\n",
    "\n",
    "Konuşmalar: \"{mesaj}\"\n",
    "\n",
    "Cevap formatı: [Evet / Hayır]\n",
    "sadece evet hayir olarak tek bir cevap ver.\n",
    "\"\"\"\n",
    "\n",
    "# === JSON DOSYASINI OKU ===\n",
    "def parse_json(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            conversations = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON dosyası okunurken hata oluştu: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for convo in conversations:\n",
    "        for msg in convo[\"messages\"]:\n",
    "            content = msg.get(\"content\")\n",
    "            if isinstance(content, dict):\n",
    "                text = content.get(\"text\", \"\")\n",
    "            else:\n",
    "                text = str(content) if content else \"\"\n",
    "            if not text or not str(text).strip():\n",
    "                continue\n",
    "            sender = \"bot\" if msg[\"sender_id\"] and msg[\"sender_id\"].startswith(\"bf\") else \"user\"\n",
    "            rows.append({\n",
    "                \"conversation_id\": convo[\"conversation_id\"],\n",
    "                \"timestamp\": msg[\"created_at\"],\n",
    "                \"sender\": sender,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# === LLM ÇAĞRISI ===\n",
    "def llm_etiketle(mesaj):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": mesaj}],\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return \"HATA\"\n",
    "\n",
    "# === VERİYİ YÜKLE VE İŞLE ===\n",
    "def main():\n",
    "    # JSON dosyasını oku\n",
    "    json_path = \"last-500-conversation-dugunbuketi.json\"\n",
    "    df = parse_json(json_path).reset_index(drop=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Hata: Veri yüklenemedi. İşlem sonlandırılıyor.\")\n",
    "        return\n",
    "    \n",
    "    # conversation_id, text, sender ve timestamp sütunlarını al\n",
    "    df = df[[\"conversation_id\", \"text\", \"sender\", \"timestamp\"]].head(171)\n",
    "\n",
    "    # Aynı conversation_id'ye sahip mesajları birleştir ve konuşma numaralarını oluştur\n",
    "    birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n",
    "        lambda x: \"\\n\".join(f\"Gönderici: {row['sender']} - Mesaj: {row['text']}\" for _, row in x.sort_values(\"timestamp\").iterrows())\n",
    "    ).reset_index(name=\"birlesik_mesaj\")\n",
    "\n",
    "    # Konuşma numaralarını oluştur (Konuşma 1, Konuşma 2, ...)\n",
    "    birlesik_konusmalar[\"konusma\"] = [f\"Konuşma {i+1}\" for i in range(len(birlesik_konusmalar))]\n",
    "\n",
    "    # Yalnızca konusma ve birlesik_mesaj sütunlarını tut\n",
    "    df_sonuc = birlesik_konusmalar[[\"konusma\", \"birlesik_mesaj\"]]\n",
    "    df_sonuc.to_csv(\"manuelLabels.csv\",index=False, encoding=\"utf-8\")\n",
    "    #Kullanıcı mesajları için sentiment ve category etiketlemesi\n",
    "    \n",
    "    df_sonuc[\"sentimen\"] = df_sonuc[\"birlesik_mesaj\"].apply(lambda x: llm_etiketle(prompt_olusturSentiment(x)))\n",
    "    df_sonuc[\"category\"] = df_sonuc[\"birlesik_mesaj\"].apply(lambda x: llm_etiketle(promptOlusturKonu(x)))\n",
    "\n",
    "    # answered etiketlemesi için birlesik_mesaj kullan\n",
    "    df_sonuc[\"answered\"] = df_sonuc[\"birlesik_mesaj\"].apply(\n",
    "        lambda x: llm_etiketle(prompt_olusturYanitladimi(x)) if x else \"HATA\"\n",
    "    )\n",
    "\n",
    "    # API çağrıları arasında gecikme\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Sonuçları kaydet\n",
    "    output_path = \"llama-3.3-70b-versatile_output1.csv\"\n",
    "    df_sonuc.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\" Etiketleme tamamlandı → {output_path} dosyasına kaydedildi.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33400e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meteh\\AppData\\Local\\Temp\\ipykernel_6532\\3254660630.py:126: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hata: Error code: 400 - {'error': {'message': 'Please reduce the length of the messages or completion.', 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "✅ Etiketleme tamamlandı → llmGemmaOutput1.csv dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Groq istemcisini başlat\n",
    "client = Groq(\n",
    "    api_key=\"your_api_key\"  # Kendi Groq API anahtarınızı kullanın\n",
    ")\n",
    "\n",
    "# === MODEL ===\n",
    "MODEL = \"gemma2-9b-it\" # Önerilen model\n",
    "\n",
    "# === PROMPT OLUŞTURMA ===\n",
    "def prompt_olusturSentiment(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki user ve bot görüşmesini mesajda botun kullanıcıya yansıtmadığı düşünceleride var bir düğün analizi uzmanı gibi analiz et analiz sonucunu yazmana gerek yok ve userın konuşma mesajlarındaki sentimentine göre sentiment  etiketini ver sadece,\n",
    "sentiment: [Pozitif / Negatif / Nötr]\n",
    "Sentimenti Tek tek mesajlardan değilde konuşmanın geneline bakarak değerlendir ama her mesajı analiz et.\n",
    "Sentiment Etiket Üretme Mantığı: Göndericinin user olduğu mesajlarda tamamen olumlu kesin olarak pozitif anlam içeriyorsa pozitif etiketle,göndericininin user olduğu mesajlarda genel olarak net bir şekilde negatif durumlar varsa negatif etiketle,bunlar dışındakileri yani user bot konuşmaları genelinde net olarak pozitif değilse, net olarak negatif değilse nötr etiketle.\n",
    "Cevabı Türkçe oluştur:Sadece sentiment=pozitif, sentiment=negatif veya sentiment=nötr gibi analiz sonucunun yorumunu yapma:\n",
    "\n",
    "Mesaj: \"{mesaj}\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def promptOlusturKonu(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki user ve bot  görüşmesi mesajını bir düğün analizi uzmanı gibi analiz et analiz sonucunu yazmana gerek yok mesj boyunca konusulan ilgili konuları liste olarak ver:\n",
    "\n",
    "Mesaj: \"{mesaj}\"\n",
    "\n",
    "Konu: . Etkinlik Türüyle İlgili Kelimeler\n",
    "(düğün, düğün salonu, düğün mekanı, kır düğünü, havuz başı düğün, otel düğünü\n",
    "kına, kına gecesi, kına organizasyonu, kına mekanı\n",
    "nişan, nişan organizasyonu, nişan mekanı, söz\n",
    "sünnet, sünnet düğünü, sünnet organizasyonu\n",
    "doğum günü, baby shower, mezuniyet, parti, after party\n",
    "2. Hizmet Türüyle İlgili Kelimeler\n",
    "organizasyon, organizasyon firması, düğün organizasyonu, kına organizasyonu\n",
    "fotoğrafçı, düğün fotoğrafçısı, video, çekim, klip\n",
    "davetiye, nikah şekeri, gelin arabası, gelin buketi, gelinlik, damatlık, saç-makyaj\n",
    "orkestra, DJ, müzik grubu, catering, yemek, kokteyl, pasta\n",
    "balayı, balayı oteli, balayı villası\n",
    "3. Mekan ve Lokasyonla İlgili Kelimeler\n",
    "il, ilçe, semt adı (ör: İstanbul, Beylikdüzü, Kadıköy, İzmir, Ankara, Bursa)\n",
    "açık alan, kapalı alan, bahçe, salon, villa, tarihi mekan, sosyal tesis, otel, tekne, havuz başı\n",
    "yakın, çevre, komşu ilçeler\n",
    "4. Tarih ve Zamanla İlgili Kelimeler\n",
    "tarih, gün, hafta sonu, hafta içi, yaz, kış, ay ismi (ör: Haziran, Temmuz)\n",
    "5. Bütçe ve Kapasiteyle İlgili Kelimeler\n",
    "kişi başı, toplam bütçe, fiyat, ücret, uygun fiyatlı, lüks, ekonomik\n",
    "davetli sayısı, kapasite, küçük grup, kalabalık, az kişi, çok kişi\n",
    "6. İkram ve Menüyle İlgili Kelimeler\n",
    "yemekli, yemeksiz, kokteyl, pasta, meşrubat, açık büfe, içecek, ikram)\n",
    "\n",
    "Türkçe olarak bir konu listesi üret, sadece listele, ve mesajda net olarak beliritlen konuyu seç mesaj dışı konular ekleme, yorum yapma: konu=[konu listesi] gibi sadece liste\n",
    "\"\"\"\n",
    "\n",
    "def prompt_olusturYanitladimi(mesaj):\n",
    "    return f\"\"\"\n",
    "Seninle Türkçe konuşuyorum. Aşağıdaki bütün müşteri bot konuşmalarını analiz et ama analiz sonuçlarını yazmana gerek yok ve gelen konuşmalarda botun userın sorularını yanıtlayıp yanıtlamadığını kontrol et konuşma boyunca userdan sonraki ilk gönderici botsa cevaplandı kabul edebilrisin:\n",
    "\n",
    "Konuşmalar: \"{mesaj}\"\n",
    "\n",
    "Cevap formatı: [Evet / Hayır]\n",
    "sadece evet hayir olarak tek bir cevap ver.\n",
    "\"\"\"\n",
    "\n",
    "# === JSON DOSYASINI OKU ===\n",
    "def parse_json(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            conversations = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON dosyası okunurken hata oluştu: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for convo in conversations:\n",
    "        for msg in convo[\"messages\"]:\n",
    "            content = msg.get(\"content\")\n",
    "            if isinstance(content, dict):\n",
    "                text = content.get(\"text\", \"\")\n",
    "            else:\n",
    "                text = str(content) if content else \"\"\n",
    "            if not text or not str(text).strip():\n",
    "                continue\n",
    "            sender = \"bot\" if msg[\"sender_id\"] and msg[\"sender_id\"].startswith(\"bf\") else \"user\"\n",
    "            rows.append({\n",
    "                \"conversation_id\": convo[\"conversation_id\"],\n",
    "                \"timestamp\": msg[\"created_at\"],\n",
    "                \"sender\": sender,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# === LLM ÇAĞRISI ===\n",
    "def llm_etiketle(mesaj):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": mesaj}],\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Hata: {e}\")\n",
    "        return \"HATA\"\n",
    "\n",
    "# === VERİYİ YÜKLE VE İŞLE ===\n",
    "def main():\n",
    "    # JSON dosyasını oku\n",
    "    json_path = \"last-500-conversation-dugunbuketi.json\"\n",
    "    df = parse_json(json_path).reset_index(drop=True)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Hata: Veri yüklenemedi. İşlem sonlandırılıyor.\")\n",
    "        return\n",
    "    \n",
    "    # conversation_id, text, sender ve timestamp sütunlarını al\n",
    "    df = df[[\"conversation_id\", \"text\", \"sender\", \"timestamp\"]].head(171)\n",
    "\n",
    "    # Aynı conversation_id'ye sahip mesajları birleştir ve konuşma numaralarını oluştur\n",
    "    birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n",
    "        lambda x: \"\\n\".join(f\"Gönderici: {row['sender']} - Mesaj: {row['text']}\" for _, row in x.sort_values(\"timestamp\").iterrows())\n",
    "    ).reset_index(name=\"birlesik_mesaj\")\n",
    "\n",
    "    # Konuşma numaralarını oluştur (Konuşma 1, Konuşma 2, ...)\n",
    "    birlesik_konusmalar[\"konusma\"] = [f\"Konuşma {i+1}\" for i in range(len(birlesik_konusmalar))]\n",
    "\n",
    "    # Yalnızca konusma ve birlesik_mesaj sütunlarını tut\n",
    "    df_sonuc = birlesik_konusmalar[[\"konusma\", \"birlesik_mesaj\"]]\n",
    "    df_sonuc.to_csv(\"manuelLabels.csv\",index=False, encoding=\"utf-8\")\n",
    "    #Kullanıcı mesajları için sentiment ve category etiketlemesi\n",
    "    \n",
    "    df_sonuc[\"sentimen\"] = df_sonuc[\"birlesik_mesaj\"].apply(lambda x: llm_etiketle(prompt_olusturSentiment(x)))\n",
    "    df_sonuc[\"category\"] = df_sonuc[\"birlesik_mesaj\"].apply(lambda x: llm_etiketle(promptOlusturKonu(x)))\n",
    "\n",
    "    # answered etiketlemesi için birlesik_mesaj kullan\n",
    "    df_sonuc[\"answered\"] = df_sonuc[\"birlesik_mesaj\"].apply(\n",
    "        lambda x: llm_etiketle(prompt_olusturYanitladimi(x)) if x else \"HATA\"\n",
    "    )\n",
    "\n",
    "    # API çağrıları arasında gecikme\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Sonuçları kaydet\n",
    "    output_path = \"llmGemmaOutput1.csv\"\n",
    "    df_sonuc.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\" Etiketleme tamamlandı → {output_path} dosyasına kaydedildi.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e56bdf",
   "metadata": {},
   "source": [
    "Kontrol etmek icin csv olusturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bf0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meteh\\AppData\\Local\\Temp\\ipykernel_6532\\3524240948.py:38: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "def parse_json(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            conversations = json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON dosyası okunurken hata oluştu: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for convo in conversations:\n",
    "        for msg in convo[\"messages\"]:\n",
    "            content = msg.get(\"content\")\n",
    "            if isinstance(content, dict):\n",
    "                text = content.get(\"text\", \"\")\n",
    "            else:\n",
    "                text = str(content) if content else \"\"\n",
    "            if not text or not str(text).strip():\n",
    "                continue\n",
    "            sender = \"bot\" if msg[\"sender_id\"] and msg[\"sender_id\"].startswith(\"bf\") else \"user\"\n",
    "            rows.append({\n",
    "                \"conversation_id\": convo[\"conversation_id\"],\n",
    "                \"timestamp\": msg[\"created_at\"],\n",
    "                \"sender\": sender,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "# JSON dosyasını oku\n",
    "json_path = \"last-500-conversation-dugunbuketi.json\"\n",
    "df = parse_json(json_path).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "# conversation_id, text, sender ve timestamp sütunlarını al\n",
    "df = df[[\"conversation_id\", \"text\", \"sender\", \"timestamp\"]].head(171)\n",
    "\n",
    "# Aynı conversation_id'ye sahip mesajları birleştir ve konuşma numaralarını oluştur\n",
    "birlesik_konusmalar = df.groupby(\"conversation_id\").apply(\n",
    "    lambda x: \"\\n\".join(f\"Gönderici: {row['sender']} - Mesaj: {row['text']}\" for _, row in x.sort_values(\"timestamp\").iterrows())\n",
    ").reset_index(name=\"birlesik_mesaj\")\n",
    "\n",
    "# Konuşma numaralarını oluştur (Konuşma 1, Konuşma 2, ...)\n",
    "birlesik_konusmalar[\"konusma\"] = [f\"Konuşma {i+1}\" for i in range(len(birlesik_konusmalar))]\n",
    "\n",
    "# Yalnızca konusma ve birlesik_mesaj sütunlarını tut\n",
    "df_sonuc = birlesik_konusmalar[[\"konusma\", \"birlesik_mesaj\"]]\n",
    "df_sonuc\n",
    "df_sonuc.to_csv(\"deneme.csv\",index=False,encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f5cfa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
